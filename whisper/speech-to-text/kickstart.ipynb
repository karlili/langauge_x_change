{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597ee73e5e2a5a1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T19:47:16.429360Z",
     "start_time": "2023-11-20T19:46:59.854269Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "\n",
    "!pip install --upgrade huggingface_hub\n",
    "\n",
    "!pip install git+https://github.com/huggingface/transformers.git accelerate\n",
    "\n",
    "!pip install torch torchvision torchaudio\n",
    "\n",
    "!pip install \"sagemaker>=2.69.0\" \"transformers==4.12.3\" --upgrade\n",
    "# using older dataset due to incompatibility of sagemaker notebook & aws-cli with > s3fs and fsspec to >= 2021.10\n",
    "!pip install  \"datasets==1.13\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44379d6790be0538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T20:17:46.597685Z",
     "start_time": "2023-11-20T19:53:57.007803Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "preprocessor_config.json: 100%|██████████| 340/340 [00:00<00:00, 53.3kB/s]\n",
      "tokenizer_config.json: 100%|██████████| 283k/283k [00:00<00:00, 1.29MB/s]\n",
      "vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 3.36MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.48M/2.48M [00:00<00:00, 5.53MB/s]\n",
      "merges.txt: 100%|██████████| 494k/494k [00:00<00:00, 2.22MB/s]\n",
      "normalizer.json: 100%|██████████| 52.7k/52.7k [00:00<00:00, 715kB/s]\n",
      "added_tokens.json: 100%|██████████| 34.6k/34.6k [00:00<00:00, 35.2MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 2.07k/2.07k [00:00<00:00, 6.35MB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' 其實都有佢嘅價值 可能會係同身份認同有關係 又或者可能佢會帶動到一個地方嘅文化旅遊 佢隱藏住同埋佢對於社會創造緊嘅價值 其實都係好重要嘅元素 史丹頓街一帶嘅唐樓活化工程已經完成 而市建局亦都話嚟緊會引入共同租住單位嘅共居模式 希望嚟時呢一度 就可以變成一個充滿文化特色 同活力嘅社區', 'chunks': [{'timestamp': (0.0, 1.4), 'text': ' 其實都有佢嘅價值'}, {'timestamp': (1.4, 4.76), 'text': ' 可能會係同身份認同有關係'}, {'timestamp': (4.76, 8.08), 'text': ' 又或者可能佢會帶動到一個地方嘅文化旅遊'}, {'timestamp': (8.08, 12.88), 'text': ' 佢隱藏住同埋佢對於社會創造緊嘅價值'}, {'timestamp': (12.88, 15.52), 'text': ' 其實都係好重要嘅元素'}, {'timestamp': (19.0, 22.6), 'text': ' 史丹頓街一帶嘅唐樓活化工程已經完成'}, {'timestamp': (22.6, 26.92), 'text': ' 而市建局亦都話嚟緊會引入共同租住單位嘅共居模式'}, {'timestamp': (26.92, 28.16), 'text': ' 希望嚟時呢一度'}, {'timestamp': (28.16, 30.08), 'text': ' 就可以變成一個充滿文化特色'}, {'timestamp': (30.08, 31.32), 'text': ' 同活力嘅社區'}]}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device =\"cpu\"\n",
    "# torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "torch_dtype=torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch_dtype, \n",
    "    low_cpu_mem_usage=True,\n",
    "     use_safetensors=True,\n",
    "    cache_dir=\"/Volumes/BACKUP/Coding/HUGGING_FACE/models\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id, cache_dir=\"/Volumes/BACKUP/Coding/HUGGING_FACE/processor\")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=1000,\n",
    "    chunk_length_s=30,\n",
    "    # batch_size=16,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    "    generate_kwargs={\"language\": \"cantonese\"}\n",
    ")\n",
    "\n",
    "\n",
    "# this is the place you modify your input - the name of the mp3 file you want to run\n",
    "result = pipe(\"source/trimmed_sample.mp3\")\n",
    "\n",
    "# then it will write the response in a json file named as the current date time\n",
    "now = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "json_object = json.dumps(result, indent=4)\n",
    "with open('output/'+now+\".json\", \"w\") as f:\n",
    "    f.write(json_object)\n",
    "\n",
    "# also it will print out the result in the following output block\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca0682e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 1.4)</td>\n",
       "      <td>其實都有佢嘅價值</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.4, 4.76)</td>\n",
       "      <td>可能會係同身份認同有關係</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(4.76, 8.08)</td>\n",
       "      <td>又或者可能佢會帶動到一個地方嘅文化旅遊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(8.08, 12.88)</td>\n",
       "      <td>佢隱藏住同埋佢對於社會創造緊嘅價值</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(12.88, 15.52)</td>\n",
       "      <td>其實都係好重要嘅元素</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(19.0, 22.6)</td>\n",
       "      <td>史丹頓街一帶嘅唐樓活化工程已經完成</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(22.6, 26.92)</td>\n",
       "      <td>而市建局亦都話嚟緊會引入共同租住單位嘅共居模式</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(26.92, 28.16)</td>\n",
       "      <td>希望嚟時呢一度</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(28.16, 30.08)</td>\n",
       "      <td>就可以變成一個充滿文化特色</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(30.08, 31.32)</td>\n",
       "      <td>同活力嘅社區</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp                      text\n",
       "0      (0.0, 1.4)                  其實都有佢嘅價值\n",
       "1     (1.4, 4.76)              可能會係同身份認同有關係\n",
       "2    (4.76, 8.08)       又或者可能佢會帶動到一個地方嘅文化旅遊\n",
       "3   (8.08, 12.88)         佢隱藏住同埋佢對於社會創造緊嘅價值\n",
       "4  (12.88, 15.52)                其實都係好重要嘅元素\n",
       "5    (19.0, 22.6)         史丹頓街一帶嘅唐樓活化工程已經完成\n",
       "6   (22.6, 26.92)   而市建局亦都話嚟緊會引入共同租住單位嘅共居模式\n",
       "7  (26.92, 28.16)                   希望嚟時呢一度\n",
       "8  (28.16, 30.08)             就可以變成一個充滿文化特色\n",
       "9  (30.08, 31.32)                    同活力嘅社區"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "df = pd.json_normalize(result, record_path =['chunks'])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83870bcd-3470-462c-abfa-bbe3ee8da924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 2.29k/2.29k [00:00<00:00, 1.70MB/s]\n",
      "model.safetensors: 100%|██████████| 1.51G/1.51G [00:14<00:00, 104MB/s] \n",
      "generation_config.json: 100%|██████████| 3.59k/3.59k [00:00<00:00, 9.54MB/s]\n",
      "preprocessor_config.json: 100%|██████████| 340/340 [00:00<00:00, 93.0kB/s]\n",
      "tokenizer_config.json: 100%|██████████| 283k/283k [00:00<00:00, 1.27MB/s]\n",
      "vocab.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 54.2MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.48M/2.48M [00:00<00:00, 5.49MB/s]\n",
      "merges.txt: 100%|██████████| 494k/494k [00:00<00:00, 113MB/s]\n",
      "normalizer.json: 100%|██████████| 52.7k/52.7k [00:00<00:00, 21.1MB/s]\n",
      "added_tokens.json: 100%|██████████| 34.6k/34.6k [00:00<00:00, 15.8MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 2.07k/2.07k [00:00<00:00, 1.25MB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE - there is a version which use an assistive model for the transciption\n",
    "# !pip install \"tokenizers>=0.14,<0.15\"\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import datetime\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoModelForSpeechSeq2Seq, AutoProcessor\n",
    "\n",
    "\n",
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device =\"mps\"\n",
    "# torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "torch_dtype=torch.float32\n",
    "\n",
    "assistant_model_id = \"distil-whisper/distil-large-v2\"\n",
    "assistant_model = AutoModelForCausalLM.from_pretrained(\n",
    "    assistant_model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "assistant_model.to(device)\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, \n",
    "    low_cpu_mem_usage=True, \n",
    "    use_safetensors=True,\n",
    "    cache_dir=\"/Volumes/BACKUP/Coding/HUGGING_FACE/models\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id, cache_dir=\"/Volumes/BACKUP/Coding/HUGGING_FACE/processor\")\n",
    "\n",
    "\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    chunk_length_s=30,\n",
    "    batch_size=1,\n",
    "    return_timestamps=True,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    "    # generate_kwargs={\"assistant_model\": assistant_model, \"language\": \"cantonese\"}\n",
    "    generate_kwargs={\"assistant_model\": assistant_model}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e654564-0c10-4357-8eb5-f57b74690201",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '中上環近半山一帶除了讓人感覺寧靜之外這裡的建築物亦是新舊交融的不說你不知這裡曾經出現過一個叫做沙雅間的社區被稱為沙雅間的社區目前並沒有完整的文獻記錄資料相傳在十九世紀史丹頓街及必烈者市街附近一大華人聚居地所建造的30間石屋而得名隨著社會變遷石屋已經不復存在現時, 方位內仍有數座大約在1950年代建成的塘樓建築分別是在2019年確定成為二級歷史建築的史丹頓街88及90號以及評級有待評估的華賢方西塘樓建築群Kara,其實當初三十間的起源是怎樣的?其實我們如果找回資料的話最早我們是在1880年的政府憲報上見到三十間這個名字我們現在在香港的地圖上面其實我們已經很難看到三十間這個名字了知道這個名字的人,大概已經60歲或以上的人才會懂得用這個名字當時在這個位置應該建了大約30間屋的建築群如果肉眼看到的痕跡,可能只有三十間街坊盂蘭會這個招牌可能就是唯一我們可以反映到以前這裡真的叫三十間的一件事上環以前其實有很多華人聚居的地方盂蘭會就是每年七月的時候會舉辦盂蘭盛會的組織他們其實是一班居民組織出來的地方盂蘭盛會對於一個華人社會來說非常重要是超渡一些孤魂野鬼令商鋪、街坊可以安心一點的傳統習俗在街道佈局上,三十間社區的特色是怎樣的?如果想理解三十間的範圍我們應該由下面的士丹頓街開始計算那個其實是一個軸心然後一直打上去到上面半山的堅島範圍中間的一個範圍其實我們也可以理解為三十間這裡當中其實都有不少的地方全部都是一些只是人行車不能進的地方包括是一些荒和里例如维延方西成王街也是人行的楼梯有些人也会将永里街计算到沙雅间的范围里面所以可以说其实沙雅间是一个步行的小区这个地方其实保留了很多那个年代50年代至60年代三至四層高的堂樓建築群長遠如何保留30間社區的歷史故事保育最好的方法是活用所以30間盂蘭盛會如果可以繼續練習繼續實踐的話就會是最好的保育方法鄰近史丹頓街一帶的堂樓原本被劃入市區重建局在2003年提出的重建計劃當中其後因應社區人士提出保留建築物的訴求市建局在2020年放棄重建計劃研究保育和活化項目裡面的建築群除了市建局的活化計劃附近亦有多個活化歷史建築的項目包括前身為荷里活道前已分警察宿舍的原創房以及前身為別列遮市街市場的香港新聞博覽館30間的範圍內或外面其實有不少歷史建築物已經活化例如包括活化成為博覽館又或者可能是做了一些文化文創的地方但是我自己覺得其實沒有一個方法一定是世界通行或者是就是叫做一定是最好的有時候其實有少少商業元素在裡面有時候都未必是一件壞事來的當然一定要有一些法例去約束住那個建築物的改动或是我们应该有一些好一些政策的配套去帮助这些建筑物继续继续继续继续在城市发展和保留旧社区和旧建筑物的历史之间可以如何取得平衡呢城市发展和保育从来都不對立一個舊建築物對於一個社區其實都有它的價值可能會與身份認同有關係又或者可能會帶動到一個地方的文化旅遊它隱藏著以及對於社會創造的價值其實都是很重要的元素史丹頓街一帶的唐紐活化工程已經完成了是重要的元素史丹頓街一帶的塘樓活化工程已經完成而市建局亦說未來會引入共同租住單位的共居模式希望將來這裡可以變成一個充滿文化特色和活力的社區', 'chunks': [{'timestamp': (0.0, 3.0), 'text': '中上環近半山一帶'}, {'timestamp': (3.0, 5.0), 'text': '除了讓人感覺寧靜之外'}, {'timestamp': (5.0, 8.0), 'text': '這裡的建築物亦是新舊交融的'}, {'timestamp': (8.0, 9.0), 'text': '不說你不知'}, {'timestamp': (9.0, 12.0), 'text': '這裡曾經出現過一個叫做沙雅間的社區'}, {'timestamp': (12.0, 15.0), 'text': '被稱為沙雅間的社區'}, {'timestamp': (15.0, 18.0), 'text': '目前並沒有完整的文獻記錄資料'}, {'timestamp': (18.0, 27.0), 'text': '相傳在十九世紀史丹頓街及必烈者市街附近一大華人聚居地所建造的30間石屋而得名'}, {'timestamp': (27.0, 29.0), 'text': '隨著社會變遷'}, {'timestamp': (29.0, 31.0), 'text': '石屋已經不復存在'}, {'timestamp': (31.0, 37.0), 'text': '現時, 方位內仍有數座大約在1950年代建成的塘樓建築'}, {'timestamp': (37.0, 41.0), 'text': '分別是在2019年確定成為二級歷史建築的'}, {'timestamp': (41.0, 48.0), 'text': '史丹頓街88及90號以及評級有待評估的華賢方西塘樓建築群'}, {'timestamp': (49.0, 53.0), 'text': 'Kara,其實當初三十間的起源是怎樣的?'}, {'timestamp': (53.0, 55.0), 'text': '其實我們如果找回資料的話'}, {'timestamp': (55.0, 59.0), 'text': '最早我們是在1880年的政府憲報上'}, {'timestamp': (59.0, 61.0), 'text': '見到三十間這個名字'}, {'timestamp': (61.0, 66.0), 'text': '我們現在在香港的地圖上面其實我們已經很難看到三十間這個名字了'}, {'timestamp': (66.0, 72.0), 'text': '知道這個名字的人,大概已經60歲或以上的人才會懂得用這個名字'}, {'timestamp': (72.0, 78.0), 'text': '當時在這個位置應該建了大約30間屋的建築群'}, {'timestamp': (78.0, 86.12), 'text': '如果肉眼看到的痕跡,可能只有三十間街坊盂蘭會這個招牌'}, {'timestamp': (86.12, 89.08), 'text': '可能就是唯一我們可以反映到'}, {'timestamp': (89.08, 91.8), 'text': '以前這裡真的叫三十間的一件事'}, {'timestamp': (91.8, 94.92), 'text': '上環以前其實有很多華人聚居的地方'}, {'timestamp': (94.92, 98.24), 'text': '盂蘭會就是每年七月的時候'}, {'timestamp': (98.24, 100.28), 'text': '會舉辦盂蘭盛會的組織'}, {'timestamp': (100.28, 109.0), 'text': '他們其實是一班居民組織出來的地方盂蘭盛會對於一個華人社會來說非常重要'}, {'timestamp': (109.0, 111.4), 'text': '是超渡一些孤魂野鬼'}, {'timestamp': (111.4, 117.0), 'text': '令商鋪、街坊可以安心一點的傳統習俗'}, {'timestamp': (117.6, 121.2), 'text': '在街道佈局上,三十間社區的特色是怎樣的?'}, {'timestamp': (121.2, 124.0), 'text': '如果想理解三十間的範圍'}, {'timestamp': (124.0, 127.04), 'text': '我們應該由下面的士丹頓街開始計算'}, {'timestamp': (127.04, 128.44), 'text': '那個其實是一個軸心'}, {'timestamp': (128.44, 132.44), 'text': '然後一直打上去到上面半山的堅島範圍'}, {'timestamp': (132.44, 133.72), 'text': '中間的一個範圍'}, {'timestamp': (133.72, 135.4), 'text': '其實我們也可以理解為三十間'}, {'timestamp': (135.4, 138.4), 'text': '這裡當中其實都有不少的地方'}, {'timestamp': (138.4, 142.08), 'text': '全部都是一些只是人行車不能進的地方'}, {'timestamp': (142.08, 145.92), 'text': '包括是一些荒和里例如维延方西'}, {'timestamp': (145.92, 148.52), 'text': '成王街也是人行的楼梯'}, {'timestamp': (148.52, 150.56), 'text': '有些人也会将永里街'}, {'timestamp': (150.56, 152.84), 'text': '计算到沙雅间的范围里面'}, {'timestamp': (152.84, 153.88), 'text': '所以可以说'}, {'timestamp': (153.88, 156.28), 'text': '其实沙雅间是一个步行的小区'}, {'timestamp': (156.28, 159.04), 'text': '这个地方其实保留了很多'}, {'timestamp': (159.04, 160.48), 'text': '那个年代'}, {'timestamp': (160.48, 169.0), 'text': '50年代至60年代三至四層高的堂樓建築群長遠如何保留30間社區的歷史故事'}, {'timestamp': (169.0, 172.0), 'text': '保育最好的方法是活用'}, {'timestamp': (172.0, 175.0), 'text': '所以30間盂蘭盛會'}, {'timestamp': (175.0, 178.0), 'text': '如果可以繼續練習'}, {'timestamp': (178.0, 179.0), 'text': '繼續實踐的話'}, {'timestamp': (179.0, 181.0), 'text': '就會是最好的保育方法'}, {'timestamp': (181.0, 184.0), 'text': '鄰近史丹頓街一帶的堂樓'}, {'timestamp': (184.0, 186.4), 'text': '原本被劃入市區重建局'}, {'timestamp': (186.4, 189.5), 'text': '在2003年提出的重建計劃當中'}, {'timestamp': (189.5, 191.76), 'text': '其後因應社區人士提出'}, {'timestamp': (191.76, 193.38), 'text': '保留建築物的訴求'}, {'timestamp': (193.38, 196.48), 'text': '市建局在2020年放棄重建計劃'}, {'timestamp': (196.48, 198.5), 'text': '研究保育和活化項目'}, {'timestamp': (198.5, 205.28), 'text': '裡面的建築群除了市建局的活化計劃附近亦有多個活化歷史建築的項目'}, {'timestamp': (205.36, 210.08), 'text': '包括前身為荷里活道前已分警察宿舍的原創房'}, {'timestamp': (210.16, 212.92), 'text': '以及前身為別列遮市街市場的'}, {'timestamp': (213.0, 214.72), 'text': '香港新聞博覽館'}, {'timestamp': (214.96, 217.2), 'text': '30間的範圍內或外面'}, {'timestamp': (217.28, 220.8), 'text': '其實有不少歷史建築物已經活化'}, {'timestamp': (227.0, 230.0), 'text': '例如包括活化成為博覽館又或者可能是做了一些文化文創的地方但是我自己覺得其實沒有一個方法'}, {'timestamp': (230.0, 233.0), 'text': '一定是世界通行或者是就是叫做一定是最好的'}, {'timestamp': (233.0, 235.0), 'text': '有時候其實有少少商業元素在裡面'}, {'timestamp': (235.0, 237.0), 'text': '有時候都未必是一件壞事來的'}, {'timestamp': (237.0, 242.0), 'text': '當然一定要有一些法例去約束住'}, {'timestamp': (242.0, 245.28), 'text': '那個建築物的改动'}, {'timestamp': (245.28, 249.6), 'text': '或是我们应该有一些好一些政策的配套'}, {'timestamp': (249.6, 252.72), 'text': '去帮助这些建筑物继续继续继续继续'}, {'timestamp': (252.72, 257.32), 'text': '在城市发展和保留旧社区和旧建筑物的历史之间'}, {'timestamp': (257.32, 258.84), 'text': '可以如何取得平衡呢'}, {'timestamp': (258.84, 265.96), 'text': '城市发展和保育从来都不對立一個舊建築物對於一個社區'}, {'timestamp': (265.96, 267.4), 'text': '其實都有它的價值'}, {'timestamp': (267.4, 270.66), 'text': '可能會與身份認同有關係'}, {'timestamp': (270.66, 272.1), 'text': '又或者可能會帶動到'}, {'timestamp': (272.1, 274.0), 'text': '一個地方的文化旅遊'}, {'timestamp': (274.0, 275.0), 'text': '它隱藏著'}, {'timestamp': (275.0, 278.76), 'text': '以及對於社會創造的價值'}, {'timestamp': (278.76, 281.46), 'text': '其實都是很重要的元素'}, {'timestamp': (284.96, 285.24), 'text': '史丹頓街一帶的唐紐活化工程已經完成了是重要的元素'}, {'timestamp': (287.52, 287.6), 'text': '史丹頓街一帶的塘樓活化工程'}, {'timestamp': (288.76, 288.84), 'text': '已經完成'}, {'timestamp': (289.92, 290.0), 'text': '而市建局亦說'}, {'timestamp': (293.04, 293.12), 'text': '未來會引入共同租住單位的共居模式'}, {'timestamp': (294.16, 294.24), 'text': '希望將來這裡'}, {'timestamp': (296.04, 296.12), 'text': '可以變成一個充滿文化特色'}, {'timestamp': (297.32, None), 'text': '和活力的社區'}]}\n"
     ]
    }
   ],
   "source": [
    "# this is the place you modify your input - the name of the mp3 file you want to run\n",
    "result = pipe(\"source/sample.mp3\")\n",
    "\n",
    "# then it will write the response in a json file named as the current date time\n",
    "# now = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "# json_object = json.dumps(result, indent=4)\n",
    "# with open('output/'+now+\".json\", \"w\") as f:\n",
    "#     f.write(json_object)\n",
    "\n",
    "# also it will print out the result in the following output block\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bd32cf5dfdb6f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:42:54.813316Z",
     "start_time": "2023-11-18T16:42:52.748851Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pyannote.audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b45080dc9467226",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T19:06:36.621050Z",
     "start_time": "2023-11-18T19:01:15.595143Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "import datetime\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "  \"pyannote/speaker-diarization-3.1\",\n",
    "  use_auth_token=\"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\")\n",
    "\n",
    "diarization = pipeline(\"source/OpenAIKeynote.mp3\")\n",
    "\n",
    "# dump the diarization output to disk using RTTM format\n",
    "now = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "with open('whisper-transcript/'+now+\"_transcript.rttm\", \"w\") as rttm:\n",
    "    diarization.write_rttm(rttm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c6c4b0d0c8250d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T16:48:15.672239Z",
     "start_time": "2023-11-18T16:48:15.669483Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(1+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
