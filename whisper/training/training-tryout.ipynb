{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee342d21",
   "metadata": {},
   "source": [
    "the original notebook is from hugging face colab notebook here (https://colab.research.google.com/github/sanchit-gandhi/notebooks/blob/main/fine_tune_whisper.ipynb)\n",
    "\n",
    "\n",
    "Make sure you have the following dependencies installed in your environment\n",
    "\n",
    "```\n",
    "pip install datasets transformers evaulate jiwer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1234f2",
   "metadata": {},
   "source": [
    "the common voice dataset is coming from here (https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0/viewer/zh-HK/train?p=84)\n",
    "\n",
    "It is part of mozilla foundation common voice project\n",
    "\n",
    "----\n",
    "\n",
    "We could use this format to prepare our own dataset to fine tune our version of whisper\n",
    "\n",
    "----\n",
    "\n",
    "If you want to re-use / avoid to download the voice file every time, you can un-comment the part which specify `cache_dir` and point it to the directory you want those file to be downloaded / already downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13205eb410405fa1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T20:09:39.997469Z",
     "start_time": "2023-11-21T20:02:41.345262Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
      "        num_rows: 5296\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
      "        num_rows: 2438\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.path.append(datasets_dir)\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "dataset_name = \"mozilla-foundation/common_voice_11_0\"\n",
    "language_to_train = 'yue'\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "common_voice[\"train\"] = load_dataset(\n",
    "  dataset_name, language_to_train, \n",
    "  split=\"train+validation\",\n",
    "  # cache_dir=\"/Volumes/BACKUP/Coding/HUGGING_FACE/datasets\"\n",
    "  )\n",
    "\n",
    "common_voice[\"test\"] = load_dataset(\n",
    "  dataset_name, language_to_train, \n",
    "  split=\"test\",  \n",
    "  # cache_dir=\"/Volumes/BACKUP/Coding/HUGGING_FACE/datasets\"\n",
    "  )\n",
    "\n",
    "print(common_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93cb70f8c8df1663",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# !pip install \"tokenizers>=0.14,<0.15\"\n",
    "\n",
    "from transformers import WhisperFeatureExtractor\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\n",
    "  \"openai/whisper-small\", \n",
    "  cache_dir=\"/Volumes/BACKUP/Coding/HUGGING_FACE/models\"\n",
    "  ) # start with the whisper small checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db962245-70f8-4288-9d9d-dc6144d90cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 805/805 [00:00<00:00, 765kB/s]\n",
      "vocab.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 836k/836k [00:00<00:00, 3.05MB/s]\n",
      "tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.48M/2.48M [00:00<00:00, 5.95MB/s]\n",
      "merges.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 494k/494k [00:00<00:00, 35.1MB/s]\n",
      "normalizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52.7k/52.7k [00:00<00:00, 42.3MB/s]\n",
      "added_tokens.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34.6k/34.6k [00:00<00:00, 29.3MB/s]\n",
      "special_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.08k/2.08k [00:00<00:00, 5.48MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperTokenizer\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", \n",
    "language=\"cantonese\", \n",
    "task=\"transcribe\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "002a1f20-0b5a-4861-92bb-ee5aceb2f8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessor_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 185k/185k [00:00<00:00, 1.90MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperProcessor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", \n",
    "language=\"cantonese\", \n",
    "task=\"transcribe\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d8a338c-6ce8-4b08-866f-dad714ba24eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'client_id': 'b472f8e5800db5f400e4b5858c16d68d205f19888992c65770b5a3852c5bfc0cb94a22890f49ca720dff40b3a1e8d466c2290a3480b916df03ea07322657f0d8', 'path': '/Volumes/BACKUP/Coding/HUGGING_FACE/datasets/downloads/extracted/512cb97225d04177325e321598281e08f0112d7fbb640b4e8d8f72d4962fae2e/yue_train_0/common_voice_yue_31209989.mp3', 'audio': {'path': '/Volumes/BACKUP/Coding/HUGGING_FACE/datasets/downloads/extracted/512cb97225d04177325e321598281e08f0112d7fbb640b4e8d8f72d4962fae2e/yue_train_0/common_voice_yue_31209989.mp3', 'array': array([ 0.00000000e+00, -0.00000000e+00,  0.00000000e+00, ...,\n",
      "       -7.54985740e-06, -5.66183462e-06, -1.75592550e-06]), 'sampling_rate': 48000}, 'sentence': 'ç¾Žåœ‹éƒ½ä¿‚å””è€ƒæ…®å–‡ï¼Œç‡ä¸‹æ¾³æ´²å…ˆ', 'up_votes': 2, 'down_votes': 0, 'age': '', 'gender': '', 'accent': '', 'locale': 'yue', 'segment': ''}\n",
      "{'client_id': 'b472f8e5800db5f400e4b5858c16d68d205f19888992c65770b5a3852c5bfc0cb94a22890f49ca720dff40b3a1e8d466c2290a3480b916df03ea07322657f0d8', 'path': '/Volumes/BACKUP/Coding/HUGGING_FACE/datasets/downloads/extracted/512cb97225d04177325e321598281e08f0112d7fbb640b4e8d8f72d4962fae2e/yue_train_0/common_voice_yue_31209989.mp3', 'audio': {'path': '/Volumes/BACKUP/Coding/HUGGING_FACE/datasets/downloads/extracted/512cb97225d04177325e321598281e08f0112d7fbb640b4e8d8f72d4962fae2e/yue_train_0/common_voice_yue_31209989.mp3', 'array': array([ 0.00000000e+00, -0.00000000e+00,  0.00000000e+00, ...,\n",
      "       -5.18230081e-06, -9.49927926e-06, -3.92721995e-06]), 'sampling_rate': 16000}, 'sentence': 'ç¾Žåœ‹éƒ½ä¿‚å””è€ƒæ…®å–‡ï¼Œç‡ä¸‹æ¾³æ´²å…ˆ', 'up_votes': 2, 'down_votes': 0, 'age': '', 'gender': '', 'accent': '', 'locale': 'yue', 'segment': ''}\n"
     ]
    }
   ],
   "source": [
    "# Preparing Data\n",
    "\n",
    "print(common_voice[\"train\"][0])\n",
    "\n",
    "# Whisper expecting the audio to be at sampling rate @16000 - this is just to make sure the sampling rate fits whisper's training\n",
    "# Since our input audio is sampled at 48kHz, we need to downsample it to 16kHz prior to passing it to the Whisper feature extractor, \n",
    "# 16kHz being the sampling rate expected by the Whisper model.\n",
    "from datasets import Audio\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "print(common_voice[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd3747",
   "metadata": {},
   "source": [
    "prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e69ad91a-725f-40a6-8dfd-7e3c64af477a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5296/5296 [02:34<00:00, 34.26 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2438/2438 [01:06<00:00, 36.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_features', 'labels'],\n",
      "        num_rows: 5296\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_features', 'labels'],\n",
      "        num_rows: 2438\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "\n",
    "\n",
    "common_voice = common_voice.map(prepare_dataset, \n",
    "  remove_columns=common_voice.column_names[\"train\"], \n",
    "  num_proc=1)\n",
    "print(common_voice)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59378d24",
   "metadata": {},
   "source": [
    "the following is the actual training and evaluation of the model\n",
    "\n",
    "using the trainer provided by huggingface\n",
    "\n",
    "Evaluation metrics: during evaluation, we want to evaluate the model using the word error rate (WER) metric. We need to define a compute_metrics function that handles this computation.\n",
    "\n",
    "Load a pre-trained checkpoint: we need to load a pre-trained checkpoint and configure it correctly for training.\n",
    "\n",
    "Define the training configuration: this will be used by the ðŸ¤— Trainer to define the training schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2be9c5d3-35df-4995-aa04-eea6fa1b1dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b87322a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86acfbcd",
   "metadata": {},
   "source": [
    "Evaluation using hugging face metric - WER (Word error rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47506d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from evaluate) (2.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from evaluate) (1.26.2)\n",
      "Requirement already satisfied: dill in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from evaluate) (2.1.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from evaluate) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from evaluate) (0.19.4)\n",
      "Requirement already satisfied: packaging in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from evaluate) (23.2)\n",
      "Collecting responses<0.19 (from evaluate)\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: filelock in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Using cached evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: responses, evaluate\n",
      "Successfully installed evaluate-0.4.1 responses-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f3bcbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.49k/4.49k [00:00<00:00, 9.36MB/s]\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1da949c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.97k/1.97k [00:00<00:00, 1.08MB/s]\n",
      "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 967M/967M [00:09<00:00, 106MB/s]  \n",
      "generation_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.84k/3.84k [00:00<00:00, 1.05MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\n",
    "  \"openai/whisper-small\", \n",
    "  # cache_dir=\"/Volumes/BACKUP/Coding/HUGGING_FACE/models\"\n",
    "  )\n",
    "\n",
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c08eb7b",
   "metadata": {},
   "source": [
    "What should be the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfa6578",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboardx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d97c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M\")\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"model/whisper-small-cantanese_\"+now,  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=4000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=False,  # if we are not using CUDA or non graphics card, use fp16=false\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"], #this would requires the tensorboardx to be installed\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=common_voice[\"train\"],\n",
    "    eval_dataset=common_voice[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    checkpoint_activations=True\n",
    ")\n",
    "\n",
    "processor.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e159c",
   "metadata": {},
   "source": [
    "The actual Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bc840b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 30/4000 [04:31<9:58:20,  9.04s/it]\n",
      "  0%|          | 1/4000 [00:34<37:58:46, 34.19s/it]\n",
      "  1%|          | 25/4000 [02:33<6:48:55,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7712, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–         | 50/4000 [05:09<6:54:01,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3822, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–         | 75/4000 [07:46<6:51:39,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9192, 'learning_rate': 1.5e-06, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–Ž         | 100/4000 [10:25<6:51:12,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3453, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 125/4000 [13:02<6:43:31,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.195, 'learning_rate': 2.5e-06, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 150/4000 [15:42<7:36:55,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1582, 'learning_rate': 3e-06, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|â–         | 175/4000 [18:23<6:47:27,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1327, 'learning_rate': 3.5e-06, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 200/4000 [21:01<6:41:45,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1401, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 225/4000 [23:41<6:42:13,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1452, 'learning_rate': 4.5e-06, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–‹         | 250/4000 [26:22<7:15:30,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1344, 'learning_rate': 5e-06, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 275/4000 [28:58<6:27:39,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.128, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 300/4000 [31:40<6:59:36,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1289, 'learning_rate': 6e-06, 'epoch': 0.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 325/4000 [34:20<6:31:17,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1131, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 350/4000 [36:58<6:27:16,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0943, 'learning_rate': 7e-06, 'epoch': 1.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 375/4000 [39:37<6:18:22,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0902, 'learning_rate': 7.500000000000001e-06, 'epoch': 1.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 400/4000 [42:19<6:21:42,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0819, 'learning_rate': 8.000000000000001e-06, 'epoch': 1.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆ         | 425/4000 [44:57<6:17:56,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0805, 'learning_rate': 8.5e-06, 'epoch': 1.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|â–ˆâ–        | 450/4000 [47:37<6:30:56,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0799, 'learning_rate': 9e-06, 'epoch': 1.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–        | 475/4000 [50:18<6:06:44,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0889, 'learning_rate': 9.5e-06, 'epoch': 1.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|â–ˆâ–Ž        | 500/4000 [52:58<6:09:13,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.086, 'learning_rate': 1e-05, 'epoch': 1.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 525/4000 [55:37<6:01:14,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0841, 'learning_rate': 9.92857142857143e-06, 'epoch': 1.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 550/4000 [58:16<6:13:39,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0886, 'learning_rate': 9.857142857142859e-06, 'epoch': 1.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|â–ˆâ–        | 575/4000 [1:00:55<5:56:45,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0872, 'learning_rate': 9.785714285714286e-06, 'epoch': 1.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 600/4000 [1:03:31<5:54:24,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0934, 'learning_rate': 9.714285714285715e-06, 'epoch': 1.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–Œ        | 625/4000 [1:06:07<5:51:57,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0915, 'learning_rate': 9.642857142857144e-06, 'epoch': 1.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|â–ˆâ–‹        | 650/4000 [1:08:43<5:48:34,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0899, 'learning_rate': 9.571428571428573e-06, 'epoch': 1.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–‹        | 675/4000 [1:11:23<5:44:07,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0634, 'learning_rate': 9.5e-06, 'epoch': 2.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 700/4000 [1:14:05<5:42:45,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0323, 'learning_rate': 9.42857142857143e-06, 'epoch': 2.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 725/4000 [1:16:43<6:27:21,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0365, 'learning_rate': 9.357142857142859e-06, 'epoch': 2.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|â–ˆâ–‰        | 750/4000 [1:19:19<5:36:49,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0353, 'learning_rate': 9.285714285714288e-06, 'epoch': 2.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|â–ˆâ–‰        | 775/4000 [1:21:55<5:33:51,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0368, 'learning_rate': 9.214285714285715e-06, 'epoch': 2.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 800/4000 [1:24:31<5:31:36,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0413, 'learning_rate': 9.142857142857144e-06, 'epoch': 2.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|â–ˆâ–ˆ        | 825/4000 [1:27:06<5:29:51,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0363, 'learning_rate': 9.071428571428573e-06, 'epoch': 2.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|â–ˆâ–ˆâ–       | 850/4000 [1:29:42<5:26:53,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0389, 'learning_rate': 9e-06, 'epoch': 2.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–       | 875/4000 [1:32:18<5:24:02,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0377, 'learning_rate': 8.92857142857143e-06, 'epoch': 2.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|â–ˆâ–ˆâ–Ž       | 900/4000 [1:34:52<4:47:41,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0343, 'learning_rate': 8.857142857142858e-06, 'epoch': 2.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|â–ˆâ–ˆâ–Ž       | 925/4000 [1:37:28<5:17:36,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0345, 'learning_rate': 8.785714285714286e-06, 'epoch': 2.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 950/4000 [1:40:03<5:16:15,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0372, 'learning_rate': 8.714285714285715e-06, 'epoch': 2.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|â–ˆâ–ˆâ–       | 975/4000 [1:42:39<5:13:34,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0412, 'learning_rate': 8.642857142857144e-06, 'epoch': 2.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 1000/4000 [1:45:14<5:10:53,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.036, 'learning_rate': 8.571428571428571e-06, 'epoch': 3.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 25%|â–ˆâ–ˆâ–Œ       | 1000/4000 [1:59:15<5:10:53,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1496237814426422, 'eval_wer': 69.63202587949858, 'eval_runtime': 840.2281, 'eval_samples_per_second': 2.902, 'eval_steps_per_second': 0.363, 'epoch': 3.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      " 26%|â–ˆâ–ˆâ–Œ       | 1025/4000 [2:02:00<5:11:32,  6.28s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0172, 'learning_rate': 8.5e-06, 'epoch': 3.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|â–ˆâ–ˆâ–‹       | 1050/4000 [2:04:36<5:05:04,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0205, 'learning_rate': 8.428571428571429e-06, 'epoch': 3.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|â–ˆâ–ˆâ–‹       | 1075/4000 [2:07:14<5:03:25,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0128, 'learning_rate': 8.357142857142858e-06, 'epoch': 3.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 1100/4000 [2:09:50<5:00:38,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0146, 'learning_rate': 8.285714285714287e-06, 'epoch': 3.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 1125/4000 [2:12:26<4:57:33,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0155, 'learning_rate': 8.214285714285714e-06, 'epoch': 3.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–‰       | 1150/4000 [2:15:04<5:18:11,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0176, 'learning_rate': 8.142857142857143e-06, 'epoch': 3.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|â–ˆâ–ˆâ–‰       | 1175/4000 [2:17:43<4:53:03,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0161, 'learning_rate': 8.071428571428572e-06, 'epoch': 3.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 1200/4000 [2:20:21<4:50:09,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0155, 'learning_rate': 8.000000000000001e-06, 'epoch': 3.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆ       | 1225/4000 [2:22:59<4:47:43,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0186, 'learning_rate': 7.928571428571429e-06, 'epoch': 3.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆâ–      | 1250/4000 [2:25:35<4:46:47,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0171, 'learning_rate': 7.857142857142858e-06, 'epoch': 3.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–      | 1275/4000 [2:28:13<4:41:11,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0175, 'learning_rate': 7.785714285714287e-06, 'epoch': 3.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 1300/4000 [2:30:48<4:39:55,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0217, 'learning_rate': 7.714285714285716e-06, 'epoch': 3.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1325/4000 [2:33:30<4:41:15,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0167, 'learning_rate': 7.642857142857143e-06, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 1350/4000 [2:36:07<4:37:34,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0086, 'learning_rate': 7.571428571428572e-06, 'epoch': 4.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|â–ˆâ–ˆâ–ˆâ–      | 1375/4000 [2:38:42<4:32:55,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0091, 'learning_rate': 7.500000000000001e-06, 'epoch': 4.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 1400/4000 [2:41:16<4:26:30,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0083, 'learning_rate': 7.428571428571429e-06, 'epoch': 4.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 1425/4000 [2:43:55<4:49:04,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0079, 'learning_rate': 7.357142857142858e-06, 'epoch': 4.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|â–ˆâ–ˆâ–ˆâ–‹      | 1450/4000 [2:46:29<4:23:19,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0075, 'learning_rate': 7.285714285714286e-06, 'epoch': 4.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|â–ˆâ–ˆâ–ˆâ–‹      | 1475/4000 [2:49:04<4:20:49,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0046, 'learning_rate': 7.2142857142857145e-06, 'epoch': 4.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1500/4000 [2:51:43<4:18:59,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.008, 'learning_rate': 7.1428571428571436e-06, 'epoch': 4.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 1525/4000 [2:54:18<4:16:28,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.01, 'learning_rate': 7.0714285714285726e-06, 'epoch': 4.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1550/4000 [2:56:53<4:13:27,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0082, 'learning_rate': 7e-06, 'epoch': 4.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 1575/4000 [2:59:29<4:11:54,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0049, 'learning_rate': 6.928571428571429e-06, 'epoch': 4.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1600/4000 [3:02:07<4:09:02,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0085, 'learning_rate': 6.857142857142858e-06, 'epoch': 4.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1625/4000 [3:04:43<4:05:59,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0091, 'learning_rate': 6.785714285714287e-06, 'epoch': 4.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1650/4000 [3:07:18<4:04:11,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0063, 'learning_rate': 6.714285714285714e-06, 'epoch': 4.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1675/4000 [3:09:54<4:01:30,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0063, 'learning_rate': 6.642857142857143e-06, 'epoch': 5.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1700/4000 [3:12:29<3:58:04,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0048, 'learning_rate': 6.571428571428572e-06, 'epoch': 5.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1725/4000 [3:15:04<3:55:38,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0042, 'learning_rate': 6.5000000000000004e-06, 'epoch': 5.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1750/4000 [3:17:39<3:52:34,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0043, 'learning_rate': 6.4285714285714295e-06, 'epoch': 5.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1775/4000 [3:20:19<3:51:40,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0027, 'learning_rate': 6.357142857142858e-06, 'epoch': 5.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1800/4000 [3:22:54<3:47:29,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0027, 'learning_rate': 6.285714285714286e-06, 'epoch': 5.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1825/4000 [3:25:29<3:44:15,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0025, 'learning_rate': 6.214285714285715e-06, 'epoch': 5.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1850/4000 [3:28:04<3:42:29,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0031, 'learning_rate': 6.142857142857144e-06, 'epoch': 5.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1875/4000 [3:30:40<3:40:03,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0027, 'learning_rate': 6.071428571428571e-06, 'epoch': 5.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1900/4000 [3:33:19<3:42:06,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0045, 'learning_rate': 6e-06, 'epoch': 5.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1925/4000 [3:35:54<3:34:36,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0042, 'learning_rate': 5.928571428571429e-06, 'epoch': 5.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1950/4000 [3:38:29<3:30:51,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0032, 'learning_rate': 5.857142857142858e-06, 'epoch': 5.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1975/4000 [3:41:04<3:30:08,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0032, 'learning_rate': 5.785714285714286e-06, 'epoch': 5.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2000/4000 [3:43:41<3:26:39,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0035, 'learning_rate': 5.7142857142857145e-06, 'epoch': 6.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2000/4000 [3:57:22<3:26:39,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17156465351581573, 'eval_wer': 71.20905782450465, 'eval_runtime': 820.7828, 'eval_samples_per_second': 2.97, 'eval_steps_per_second': 0.372, 'epoch': 6.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2025/4000 [4:00:12<3:25:23,  6.24s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0023, 'learning_rate': 5.6428571428571435e-06, 'epoch': 6.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2050/4000 [4:02:47<3:20:44,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0017, 'learning_rate': 5.571428571428572e-06, 'epoch': 6.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2075/4000 [4:05:21<3:18:01,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0015, 'learning_rate': 5.500000000000001e-06, 'epoch': 6.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2100/4000 [4:07:56<3:15:40,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.003, 'learning_rate': 5.428571428571429e-06, 'epoch': 6.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2125/4000 [4:10:34<3:14:21,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0015, 'learning_rate': 5.357142857142857e-06, 'epoch': 6.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2150/4000 [4:13:08<3:10:04,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0018, 'learning_rate': 5.285714285714286e-06, 'epoch': 6.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 2175/4000 [4:15:46<3:07:31,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0029, 'learning_rate': 5.214285714285715e-06, 'epoch': 6.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2200/4000 [4:18:24<3:13:19,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0033, 'learning_rate': 5.142857142857142e-06, 'epoch': 6.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 2225/4000 [4:21:01<3:02:09,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0012, 'learning_rate': 5.071428571428571e-06, 'epoch': 6.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2250/4000 [4:23:35<3:00:06,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0011, 'learning_rate': 5e-06, 'epoch': 6.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2275/4000 [4:26:13<2:56:54,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0019, 'learning_rate': 4.928571428571429e-06, 'epoch': 6.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2300/4000 [4:28:50<2:57:21,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0028, 'learning_rate': 4.857142857142858e-06, 'epoch': 6.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 2325/4000 [4:31:24<2:51:15,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0013, 'learning_rate': 4.785714285714287e-06, 'epoch': 7.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2350/4000 [4:34:01<2:49:47,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0016, 'learning_rate': 4.714285714285715e-06, 'epoch': 7.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2375/4000 [4:36:36<2:47:28,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0008, 'learning_rate': 4.642857142857144e-06, 'epoch': 7.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2400/4000 [4:39:10<2:44:32,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0012, 'learning_rate': 4.571428571428572e-06, 'epoch': 7.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2425/4000 [4:41:48<2:41:45,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0011, 'learning_rate': 4.5e-06, 'epoch': 7.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2450/4000 [4:44:23<2:39:15,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0011, 'learning_rate': 4.428571428571429e-06, 'epoch': 7.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2475/4000 [4:47:01<2:38:56,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.001, 'learning_rate': 4.357142857142857e-06, 'epoch': 7.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2500/4000 [4:49:36<2:35:21,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0009, 'learning_rate': 4.2857142857142855e-06, 'epoch': 7.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2525/4000 [4:52:10<2:31:59,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0006, 'learning_rate': 4.2142857142857145e-06, 'epoch': 7.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2550/4000 [4:54:46<2:32:13,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0014, 'learning_rate': 4.1428571428571435e-06, 'epoch': 7.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 2575/4000 [4:57:20<2:26:30,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0017, 'learning_rate': 4.071428571428572e-06, 'epoch': 7.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2600/4000 [4:59:55<2:23:42,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.001, 'learning_rate': 4.000000000000001e-06, 'epoch': 7.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2625/4000 [5:02:33<2:33:54,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0006, 'learning_rate': 3.928571428571429e-06, 'epoch': 7.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2650/4000 [5:05:12<2:20:30,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0007, 'learning_rate': 3.857142857142858e-06, 'epoch': 8.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2675/4000 [5:07:47<2:16:20,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0014, 'learning_rate': 3.785714285714286e-06, 'epoch': 8.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2700/4000 [5:10:21<2:13:42,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'learning_rate': 3.7142857142857146e-06, 'epoch': 8.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 2725/4000 [5:12:58<2:10:59,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'learning_rate': 3.642857142857143e-06, 'epoch': 8.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2750/4000 [5:15:33<2:09:05,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0007, 'learning_rate': 3.5714285714285718e-06, 'epoch': 8.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2775/4000 [5:18:08<2:05:40,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'learning_rate': 3.5e-06, 'epoch': 8.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2800/4000 [5:20:42<2:03:45,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'learning_rate': 3.428571428571429e-06, 'epoch': 8.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 2825/4000 [5:23:17<2:00:36,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'learning_rate': 3.357142857142857e-06, 'epoch': 8.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2850/4000 [5:25:53<1:58:03,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0008, 'learning_rate': 3.285714285714286e-06, 'epoch': 8.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2875/4000 [5:28:27<1:55:32,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'learning_rate': 3.2142857142857147e-06, 'epoch': 8.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2900/4000 [5:31:02<1:53:17,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'learning_rate': 3.142857142857143e-06, 'epoch': 8.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 2925/4000 [5:33:42<1:53:02,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'learning_rate': 3.071428571428572e-06, 'epoch': 8.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2950/4000 [5:36:16<1:47:49,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0009, 'learning_rate': 3e-06, 'epoch': 8.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2975/4000 [5:38:55<2:04:45,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0006, 'learning_rate': 2.928571428571429e-06, 'epoch': 8.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3000/4000 [5:41:30<1:42:59,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'learning_rate': 2.8571428571428573e-06, 'epoch': 9.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3000/4000 [5:55:58<1:42:59,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18760216236114502, 'eval_wer': 64.33481601293974, 'eval_runtime': 868.3804, 'eval_samples_per_second': 2.808, 'eval_steps_per_second': 0.351, 'epoch': 9.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/BACKUP/Python_VENV/langauge_x_change/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3025/4000 [5:58:40<1:40:55,  6.21s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0006, 'learning_rate': 2.785714285714286e-06, 'epoch': 9.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3050/4000 [6:01:14<1:37:09,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 2.7142857142857144e-06, 'epoch': 9.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 3075/4000 [6:03:53<1:44:39,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 2.642857142857143e-06, 'epoch': 9.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3100/4000 [6:06:27<1:32:50,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 2.571428571428571e-06, 'epoch': 9.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 3125/4000 [6:09:06<1:31:19,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 2.5e-06, 'epoch': 9.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3150/4000 [6:11:42<1:28:05,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'learning_rate': 2.428571428571429e-06, 'epoch': 9.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 3175/4000 [6:14:23<1:25:16,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 2.3571428571428574e-06, 'epoch': 9.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3200/4000 [6:16:58<1:22:51,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'learning_rate': 2.285714285714286e-06, 'epoch': 9.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 3225/4000 [6:19:36<1:21:04,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0014, 'learning_rate': 2.2142857142857146e-06, 'epoch': 9.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3250/4000 [6:22:11<1:17:08,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 2.1428571428571427e-06, 'epoch': 9.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3275/4000 [6:24:49<1:15:48,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 2.0714285714285717e-06, 'epoch': 9.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3300/4000 [6:27:24<1:11:55,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 2.0000000000000003e-06, 'epoch': 9.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 3325/4000 [6:30:02<1:09:33,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 1.928571428571429e-06, 'epoch': 10.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3350/4000 [6:32:37<1:07:05,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 1.8571428571428573e-06, 'epoch': 10.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3375/4000 [6:35:12<1:04:46,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 1.7857142857142859e-06, 'epoch': 10.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3400/4000 [6:37:46<1:01:51,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 1.7142857142857145e-06, 'epoch': 10.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 3425/4000 [6:40:20<59:11,  6.18s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0006, 'learning_rate': 1.642857142857143e-06, 'epoch': 10.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3450/4000 [6:42:55<56:44,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 1.5714285714285714e-06, 'epoch': 10.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 3475/4000 [6:45:30<54:09,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 1.5e-06, 'epoch': 10.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3500/4000 [6:48:05<51:38,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 1.4285714285714286e-06, 'epoch': 10.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3525/4000 [6:50:39<49:01,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 1.3571428571428572e-06, 'epoch': 10.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3550/4000 [6:53:17<46:52,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0006, 'learning_rate': 1.2857142857142856e-06, 'epoch': 10.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 3575/4000 [6:55:51<43:40,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 1.2142857142857144e-06, 'epoch': 10.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3600/4000 [6:58:29<41:08,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 1.142857142857143e-06, 'epoch': 10.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3625/4000 [7:01:09<39:23,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 1.0714285714285714e-06, 'epoch': 10.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3650/4000 [7:03:46<35:54,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 1.0000000000000002e-06, 'epoch': 11.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3675/4000 [7:06:19<33:19,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'learning_rate': 9.285714285714287e-07, 'epoch': 11.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3700/4000 [7:08:53<30:49,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 8.571428571428572e-07, 'epoch': 11.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 3725/4000 [7:11:32<29:02,  6.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 7.857142857142857e-07, 'epoch': 11.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3750/4000 [7:14:06<25:38,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0003, 'learning_rate': 7.142857142857143e-07, 'epoch': 11.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3775/4000 [7:16:44<27:16,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0005, 'learning_rate': 6.428571428571428e-07, 'epoch': 11.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3800/4000 [7:19:22<20:59,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 5.714285714285715e-07, 'epoch': 11.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 3825/4000 [7:21:56<17:55,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0003, 'learning_rate': 5.000000000000001e-07, 'epoch': 11.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3850/4000 [7:24:32<15:24,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0003, 'learning_rate': 4.285714285714286e-07, 'epoch': 11.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3875/4000 [7:27:09<12:49,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 3.5714285714285716e-07, 'epoch': 11.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3900/4000 [7:29:45<10:16,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0003, 'learning_rate': 2.8571428571428575e-07, 'epoch': 11.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 3925/4000 [7:32:22<07:44,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 2.142857142857143e-07, 'epoch': 11.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3950/4000 [7:34:56<05:08,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 1.4285714285714287e-07, 'epoch': 11.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 3975/4000 [7:37:30<02:35,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 7.142857142857144e-08, 'epoch': 12.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4000/4000 [7:40:04<00:00,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0004, 'learning_rate': 0.0, 'epoch': 12.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4000/4000 [7:54:19<00:00,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19237440824508667, 'eval_wer': 64.4561261625556, 'eval_runtime': 854.6178, 'eval_samples_per_second': 2.853, 'eval_steps_per_second': 0.357, 'epoch': 12.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['proj_out.weight'].\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4000/4000 [7:54:30<00:00,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 28470.8418, 'train_samples_per_second': 2.248, 'train_steps_per_second': 0.14, 'train_loss': 0.04882594305602834, 'epoch': 12.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef21b87e",
   "metadata": {},
   "source": [
    "if you need to push the model to hugging face hub, run the following block\n",
    "\n",
    "```\n",
    "pip install --upgrade huggingface_hub\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3d3557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is optional. but it would allow you to upload the model to hugging face space later on\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0a8fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to push\n",
    "\n",
    "#the following arguments are needed only when we are pushing the model to hugging face hub\n",
    "kwargs = {\n",
    "    \"dataset_tags\": \"mozilla-foundation/common_voice_11_0\",\n",
    "    \"dataset\": \"Common Voice 11.0\",  # a 'pretty' name for the training dataset\n",
    "    \"dataset_args\": \"config: hi, split: test\",\n",
    "    \"language\": \"Cantonese\",\n",
    "    \"model_name\": \"[language-x-change] Custom Whisper for Cantanese\",  # a 'pretty' name for our model\n",
    "    \"finetuned_from\": \"openai/whisper-small\",\n",
    "    \"tasks\": \"automatic-speech-recognition\",\n",
    "    \"tags\": \"hf-asr-leaderboard\",\n",
    "}\n",
    "\n",
    "trainer.push_to_hub(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b895521a",
   "metadata": {},
   "source": [
    "The following is only needed when we want to deploy a runnable version with our uploaded model on hugging face spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a427339",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2582a1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import gradio as gr\n",
    "\n",
    "pipe = pipeline(model=\"your-own-model\")  # change to \"your-username/the-name-you-picked\"\n",
    "\n",
    "def transcribe(audio):\n",
    "    text = pipe(audio)[\"text\"]\n",
    "    return text\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=transcribe,\n",
    "    inputs=gr.Audio(source=\"microphone\", type=\"filepath\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Whisper Small Hindi\",\n",
    "    description=\"Realtime demo for Hindi speech recognition using a fine-tuned Whisper small model.\",\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1531bd73",
   "metadata": {},
   "source": [
    "to use the model we just compiled (https://huggingface.co/docs/transformers/tasks/asr#inference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37a6db6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' å…¶å¯¦éƒ½æœ‰ä½¢å˜…åƒ¹å€¼å•¦å¯èƒ½æœƒä¿‚åŒèº«ç²‰èªåŒæœ‰é—œä¿‚å•¦åˆæˆ–è€…å¯èƒ½ä½¢æœƒå¤§å‹•åˆ°ä¸€å€‹åœ°æ–¹å˜…æ–‡åŒ–æ—…æ¸¸å•¦ä½¢éš•è—ä½åŒåŸ‹ä½¢å°æ–¼å‘¢å€‹ç¤¾æœƒå‰µé€ ç·Šå˜…åƒ¹å€¼å…¶å¯¦éƒ½ä¿‚å¥½é‡è¦å˜…å…ƒç´ åšŸå˜… å¸‚å–®å®šåŠ ä¸€å¤§å˜…å”å·žæ´»ç™¼å·¥ç¨‹å·²ç¶“å®Œæˆå˜…å˜ž è€Œå¸‚å»ºå…±äº¦éƒ½è©±åšŸç·Šæœƒå¼•å…¥å…±åŒç§Ÿä½å–®ä½å˜…å…±å±…æ¨¡å¼å¸Œæœ›åº•æ™‚å‘¢åº¦å‘¢å°±å¯ä»¥è®Šæˆä¸€å€‹å……æ»¿æ–‡åŒ–ç‰¹è‰²åŒåŸ‹æ´»åŠ›å˜…ç¤¾å€', 'chunks': [{'timestamp': (0.0, 1.4), 'text': ' å…¶å¯¦éƒ½æœ‰ä½¢å˜…åƒ¹å€¼å•¦'}, {'timestamp': (1.4, 4.68), 'text': 'å¯èƒ½æœƒä¿‚åŒèº«ç²‰èªåŒæœ‰é—œä¿‚å•¦'}, {'timestamp': (4.68, 8.0), 'text': 'åˆæˆ–è€…å¯èƒ½ä½¢æœƒå¤§å‹•åˆ°ä¸€å€‹åœ°æ–¹å˜…æ–‡åŒ–æ—…æ¸¸å•¦'}, {'timestamp': (8.0, 15.04), 'text': 'ä½¢éš•è—ä½åŒåŸ‹ä½¢å°æ–¼å‘¢å€‹ç¤¾æœƒå‰µé€ ç·Šå˜…åƒ¹å€¼å…¶å¯¦éƒ½ä¿‚å¥½é‡è¦å˜…å…ƒç´ åšŸå˜…'}, {'timestamp': (19.04, 22.64), 'text': ' å¸‚å–®å®šåŠ ä¸€å¤§å˜…å”å·žæ´»ç™¼å·¥ç¨‹å·²ç¶“å®Œæˆå˜…å˜ž'}, {'timestamp': (22.64, 26.88), 'text': ' è€Œå¸‚å»ºå…±äº¦éƒ½è©±åšŸç·Šæœƒå¼•å…¥å…±åŒç§Ÿä½å–®ä½å˜…å…±å±…æ¨¡å¼'}, {'timestamp': (0.0, 4.32), 'text': 'å¸Œæœ›åº•æ™‚å‘¢åº¦å‘¢å°±å¯ä»¥è®Šæˆä¸€å€‹å……æ»¿æ–‡åŒ–ç‰¹è‰²åŒåŸ‹æ´»åŠ›å˜…ç¤¾å€'}]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoModelForSpeechSeq2Seq, AutoProcessor\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "path = \"model/whisper-small-cantanese/checkpoint-4000\"\n",
    "processor_path = \"model/whisper-small-cantanese\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "   path, \n",
    "   local_files_only=True,\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(processor_path)\n",
    "\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", \n",
    "    model=model,  \n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    # chunk_length_s=10,\n",
    "    max_new_tokens=1000,\n",
    "   #  batch_size=16,\n",
    "    return_timestamps=True\n",
    "   )\n",
    "transcriber.tokenizer.get_decoder_prompt_ids(language='cantonese', task=\"transcribe\")\n",
    "result = transcriber(\"source/trimmed_sample.mp3\")\n",
    "\n",
    "now = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "json_object = json.dumps(result, indent=4)\n",
    "with open('output/'+now+\".json\", \"w\") as f:\n",
    "    f.write(json_object)\n",
    "\n",
    "# also it will print out the result in the following output block\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beb5b8e",
   "metadata": {},
   "source": [
    "install the following dependencies for plotting and tabulation\n",
    "\n",
    "```\n",
    "pip install pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b202c133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 1.4)</td>\n",
       "      <td>å…¶å¯¦éƒ½æœ‰ä½¢å˜…åƒ¹å€¼å•¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1.4, 4.68)</td>\n",
       "      <td>å¯èƒ½æœƒä¿‚åŒèº«ç²‰èªåŒæœ‰é—œä¿‚å•¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(4.68, 8.0)</td>\n",
       "      <td>åˆæˆ–è€…å¯èƒ½ä½¢æœƒå¤§å‹•åˆ°ä¸€å€‹åœ°æ–¹å˜…æ–‡åŒ–æ—…æ¸¸å•¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(8.0, 15.04)</td>\n",
       "      <td>ä½¢éš•è—ä½åŒåŸ‹ä½¢å°æ–¼å‘¢å€‹ç¤¾æœƒå‰µé€ ç·Šå˜…åƒ¹å€¼å…¶å¯¦éƒ½ä¿‚å¥½é‡è¦å˜…å…ƒç´ åšŸå˜…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(19.04, 22.64)</td>\n",
       "      <td>å¸‚å–®å®šåŠ ä¸€å¤§å˜…å”å·žæ´»ç™¼å·¥ç¨‹å·²ç¶“å®Œæˆå˜…å˜ž</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(22.64, 26.88)</td>\n",
       "      <td>è€Œå¸‚å»ºå…±äº¦éƒ½è©±åšŸç·Šæœƒå¼•å…¥å…±åŒç§Ÿä½å–®ä½å˜…å…±å±…æ¨¡å¼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0.0, 4.32)</td>\n",
       "      <td>å¸Œæœ›åº•æ™‚å‘¢åº¦å‘¢å°±å¯ä»¥è®Šæˆä¸€å€‹å……æ»¿æ–‡åŒ–ç‰¹è‰²åŒåŸ‹æ´»åŠ›å˜…ç¤¾å€</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        timestamp                             text\n",
       "0      (0.0, 1.4)                        å…¶å¯¦éƒ½æœ‰ä½¢å˜…åƒ¹å€¼å•¦\n",
       "1     (1.4, 4.68)                    å¯èƒ½æœƒä¿‚åŒèº«ç²‰èªåŒæœ‰é—œä¿‚å•¦\n",
       "2     (4.68, 8.0)             åˆæˆ–è€…å¯èƒ½ä½¢æœƒå¤§å‹•åˆ°ä¸€å€‹åœ°æ–¹å˜…æ–‡åŒ–æ—…æ¸¸å•¦\n",
       "3    (8.0, 15.04)  ä½¢éš•è—ä½åŒåŸ‹ä½¢å°æ–¼å‘¢å€‹ç¤¾æœƒå‰µé€ ç·Šå˜…åƒ¹å€¼å…¶å¯¦éƒ½ä¿‚å¥½é‡è¦å˜…å…ƒç´ åšŸå˜…\n",
       "4  (19.04, 22.64)              å¸‚å–®å®šåŠ ä¸€å¤§å˜…å”å·žæ´»ç™¼å·¥ç¨‹å·²ç¶“å®Œæˆå˜…å˜ž\n",
       "5  (22.64, 26.88)          è€Œå¸‚å»ºå…±äº¦éƒ½è©±åšŸç·Šæœƒå¼•å…¥å…±åŒç§Ÿä½å–®ä½å˜…å…±å±…æ¨¡å¼\n",
       "6     (0.0, 4.32)      å¸Œæœ›åº•æ™‚å‘¢åº¦å‘¢å°±å¯ä»¥è®Šæˆä¸€å€‹å……æ»¿æ–‡åŒ–ç‰¹è‰²åŒåŸ‹æ´»åŠ›å˜…ç¤¾å€"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "df = pd.json_normalize(result, record_path =['chunks'])\n",
    "display(df)\n",
    "\n",
    "# show df in a tablular format\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
